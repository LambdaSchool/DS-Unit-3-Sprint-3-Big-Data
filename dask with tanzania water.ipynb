{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "\n",
    "t_water = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/jdills26/Tanzania-water-table/master/training_set_values.csv\"\n",
    ")\n",
    "t_water_tgt = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/jdills26/Tanzania-water-table/master/training_set_labels.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning pandas dataframe into dask dataframe\n",
    "t_water['target']=t_water_tgt['status_group']\n",
    "wd=dd.from_pandas(t_water, npartitions=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_dict = {\n",
    "    \"Arusha\": 2,\n",
    "    \"Dar es Salaam\": 7,\n",
    "    \"Dodoma\": 1,\n",
    "    \"Iringa\": 11,\n",
    "    \"Kagera\": 18,\n",
    "    \"Kigoma\": 16,\n",
    "    \"Kilimanjaro\": 3,\n",
    "    \"Lindi\": 80,\n",
    "    \"Manyara\": 21,\n",
    "    \"Mara\": 20,\n",
    "    \"Mbeya\": 12,\n",
    "    \"Morogoro\": 5,\n",
    "    \"Mtwara\": 90,\n",
    "    \"Mwanza\": 19,\n",
    "    \"Pwani\": 6,\n",
    "    \"Rukwa\": 15,\n",
    "    \"Ruvuma\": 10,\n",
    "    \"Shinyanga\": 17,\n",
    "    \"Singida\": 13,\n",
    "    \"Tabora\": 14,\n",
    "    \"Tanga\": 4,\n",
    "}\n",
    "\n",
    "\n",
    "def clean_region(frame):\n",
    "    frame[\"region_code\"] = frame[\"region\"].map(region_dict)\n",
    "\n",
    "\n",
    "clean_region(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe to work out average longitude, latitude, gps_height by region\n",
    "# wd['my_area_code']=100*wd['region_code']+wd['district_code']\n",
    "averages = (\n",
    "    wd[wd[\"longitude\"] != 0]\n",
    "    .groupby([\"region_code\"])[[\"longitude\", \"latitude\"]]\n",
    "    .mean()\n",
    "    .compute()\n",
    ")\n",
    "longitude_map = averages[\"longitude\"].to_dict()\n",
    "latitude_map = averages[\"latitude\"].to_dict()\n",
    "wd[\"avg_longitude\"] = wd[\"region_code\"].map(longitude_map)\n",
    "wd[\"avg_latitude\"] = wd[\"region_code\"].map(latitude_map)\n",
    "wd[\"new_longitude\"] = wd[\"longitude\"].where(wd[\"longitude\"] != 0, wd[\"avg_longitude\"])\n",
    "wd[\"new_latitude\"] = wd[\"latitude\"].where(wd[\"longitude\"] != 0, wd[\"avg_latitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates\n",
    "wd[\"date_recorded\"] = dd.to_datetime(wd[\"date_recorded\"], format=\"%Y-%m-%d\")\n",
    "wd[\"month\"] = wd[\"date_recorded\"].map(lambda x: x.month)\n",
    "wd[\"year\"] = wd[\"date_recorded\"].map(lambda x: x.year)\n",
    "wd[\"date_recorded\"] = wd[\"date_recorded\"].map(lambda x: x.toordinal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd[\"rot45X\"] = .707* wd[\"new_latitude\"] - .707* wd[\"new_longitude\"]\n",
    "wd[\"rot30X\"]  = (1.732/2)* wd[\"new_latitude\"] - (1./2)* wd[\"new_longitude\"]\n",
    "wd[\"rot60X\"]  = (1./2)* wd[\"new_latitude\"] - (1.732/2)* wd[\"new_longitude\"]\n",
    "wd[\"radial_r\"] = np.sqrt( np.power(wd[\"new_latitude\"],2) + np.power(wd[\"new_longitude\"],2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd['radial_r'].isna().sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"basin\",\n",
    "    \"scheme_management\",\n",
    "    \"extraction_type_group\",\n",
    "    \"extraction_type_class\",\n",
    "    \"month\",\n",
    "    \"payment\",\n",
    "    \"quantity\",\n",
    "    \"source\",\n",
    "    \"waterpoint_type\",\n",
    "    \"amount_tsh\",\n",
    "    \"gps_height\",\n",
    "    \"new_longitude\",\n",
    "    \"new_latitude\",\n",
    "    \"population\",\n",
    "    \"construction_year\",\n",
    "    \"district_code\",\n",
    "    \"region_code\",\n",
    "    \"date_recorded\",\n",
    "    \"permit\",\n",
    "    \"public_meeting\",\n",
    "    \"rot45X\",\n",
    "    \"radial_r\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wd[features]\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from dask_ml.preprocessing import (\n",
    "    RobustScaler,\n",
    "    Categorizer,\n",
    "    DummyEncoder,\n",
    "    OrdinalEncoder,\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "preprocessor = make_pipeline(\n",
    "    Categorizer(), DummyEncoder(), RobustScaler()\n",
    ")  # ,SimpleImputer()#ce.OrdinalEncoder(),\n",
    "\n",
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 59400)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns),(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dict={'functional':1,'non functional':0,'functional needs repair':2}\n",
    "y=wd['target'].map(y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just to check it works on dask collection\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i had to use .values here to get this to run.  am not sure why as docs say\n",
    "# should work straight on the dask dataframe\n",
    "from dask_ml.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distributions_f = {\n",
    "    \"n_estimators\": randint(100, 140),\n",
    "    \"max_depth\": randint(16, 23),\n",
    "}\n",
    "\n",
    "search_f = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(\n",
    "        criterion=\"entropy\", warm_start=True, oob_score=True, n_jobs=-1, random_state=42\n",
    "    ),\n",
    "    param_distributions=param_distributions_f,\n",
    "    n_iter=10,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    cv=3,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "search_f.fit(X.values, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 21, 'n_estimators': 133}</td>\n",
       "      <td>45.065397</td>\n",
       "      <td>0.688802</td>\n",
       "      <td>4.182663</td>\n",
       "      <td>1.018419</td>\n",
       "      <td>0.807071</td>\n",
       "      <td>0.807020</td>\n",
       "      <td>0.805808</td>\n",
       "      <td>0.806633</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>1</td>\n",
       "      <td>0.964293</td>\n",
       "      <td>0.964848</td>\n",
       "      <td>0.966566</td>\n",
       "      <td>0.965236</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>21</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 18, 'n_estimators': 126}</td>\n",
       "      <td>41.029127</td>\n",
       "      <td>0.779754</td>\n",
       "      <td>4.678832</td>\n",
       "      <td>1.112311</td>\n",
       "      <td>0.805909</td>\n",
       "      <td>0.808434</td>\n",
       "      <td>0.805354</td>\n",
       "      <td>0.806566</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>2</td>\n",
       "      <td>0.919141</td>\n",
       "      <td>0.922727</td>\n",
       "      <td>0.923687</td>\n",
       "      <td>0.921852</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>18</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 18, 'n_estimators': 127}</td>\n",
       "      <td>47.489294</td>\n",
       "      <td>5.537750</td>\n",
       "      <td>3.705850</td>\n",
       "      <td>0.465812</td>\n",
       "      <td>0.805707</td>\n",
       "      <td>0.808283</td>\n",
       "      <td>0.805303</td>\n",
       "      <td>0.806431</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>3</td>\n",
       "      <td>0.918889</td>\n",
       "      <td>0.922652</td>\n",
       "      <td>0.923939</td>\n",
       "      <td>0.921827</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>18</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 21, 'n_estimators': 101}</td>\n",
       "      <td>34.443672</td>\n",
       "      <td>4.335718</td>\n",
       "      <td>4.559653</td>\n",
       "      <td>0.843609</td>\n",
       "      <td>0.807323</td>\n",
       "      <td>0.807374</td>\n",
       "      <td>0.804293</td>\n",
       "      <td>0.806330</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>4</td>\n",
       "      <td>0.963611</td>\n",
       "      <td>0.964646</td>\n",
       "      <td>0.966970</td>\n",
       "      <td>0.965076</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>21</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 19, 'n_estimators': 134}</td>\n",
       "      <td>50.118286</td>\n",
       "      <td>2.508439</td>\n",
       "      <td>4.206169</td>\n",
       "      <td>0.390526</td>\n",
       "      <td>0.806111</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.804444</td>\n",
       "      <td>0.806296</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>5</td>\n",
       "      <td>0.936540</td>\n",
       "      <td>0.939823</td>\n",
       "      <td>0.940379</td>\n",
       "      <td>0.938914</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>19</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   params  mean_fit_time  std_fit_time  \\\n",
       "8  {'max_depth': 21, 'n_estimators': 133}      45.065397      0.688802   \n",
       "5  {'max_depth': 18, 'n_estimators': 126}      41.029127      0.779754   \n",
       "1  {'max_depth': 18, 'n_estimators': 127}      47.489294      5.537750   \n",
       "6  {'max_depth': 21, 'n_estimators': 101}      34.443672      4.335718   \n",
       "3  {'max_depth': 19, 'n_estimators': 134}      50.118286      2.508439   \n",
       "\n",
       "   mean_score_time  std_score_time  split0_test_score  split1_test_score  \\\n",
       "8         4.182663        1.018419           0.807071           0.807020   \n",
       "5         4.678832        1.112311           0.805909           0.808434   \n",
       "1         3.705850        0.465812           0.805707           0.808283   \n",
       "6         4.559653        0.843609           0.807323           0.807374   \n",
       "3         4.206169        0.390526           0.806111           0.808333   \n",
       "\n",
       "   split2_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "8           0.805808         0.806633        0.000584                1   \n",
       "5           0.805354         0.806566        0.001341                2   \n",
       "1           0.805303         0.806431        0.001320                3   \n",
       "6           0.804293         0.806330        0.001441                4   \n",
       "3           0.804444         0.806296        0.001593                5   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "8            0.964293            0.964848            0.966566   \n",
       "5            0.919141            0.922727            0.923687   \n",
       "1            0.918889            0.922652            0.923939   \n",
       "6            0.963611            0.964646            0.966970   \n",
       "3            0.936540            0.939823            0.940379   \n",
       "\n",
       "   mean_train_score  std_train_score param_max_depth param_n_estimators  \n",
       "8          0.965236         0.000967              21                133  \n",
       "5          0.921852         0.001956              18                126  \n",
       "1          0.921827         0.002143              18                127  \n",
       "6          0.965076         0.001404              21                101  \n",
       "3          0.938914         0.001694              19                134  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search_f.cv_results_).sort_values(by='rank_test_score').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dask.dataframe.core.DataFrame, dask.dataframe.core.Series)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X),type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.array.core.Array"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
