Lambda School Data Science - Big Data

Apache Spark, day 1 - Assignment
1. Sign up for Databricks Community Edition
Today we’ll continue our tour of different cloud notebook platforms!

We’ll use Databricks Community Edition today, because it’s:

Free! (Unlimited credits)
Preconfigured, convenient
Preloaded with datasets
Made for Spark, by its creators
Please submit the form here, to sign up for your free account.

“Company Name” = “Lambda School”
“What is your intended use case?” = “Personal - Learning Spark”
2. Sign in to Databricks Community Edition
3. Explore the Quickstart tutorial
From the Welcome to databricks page, click on Explore the Quickstart tutorial.

This will open a notebook. Follow the instructions to Create a quickstart cluster, Attach the notebook to the cluster and run all commands in the notebook.

(You don't have to type the commands yourself from scratch. The purpose here is just to see a preview of what you can do with Spark and Databricks, and verify it's working for you. Note that Databricks documentation has more information about this tutorial.)

4. Create a notebook (Scala)
5. Estimate Pi
In your notebook, run the Pi Estimation example (in Scala) from the Apache Spark Examples.

(First you'll need to assign an integer value to the NUM_SAMPLES constant.)

How does the code compare to the monte_carlo_pi example on Numba's homepage?

(Regarding the performance: Note that Databricks Community Edition is a "Single cluster limited to 6GB and no worker nodes.")

6. Do exercises from Spark: The Definitive Guide
First, read Spark: The Definitive Guide excerpts, Pages 1-21.

Then, in your notebook, do the code exercises from Spark: The Definitive Guide, Chapter 2: A Gentle Introduction to Spark.

Important! Note these instructions from the repo README:

Rather than you having to upload all of the data yourself, you simply have to change the path in each chapter from /data to /databricks-datasets/definitive-guide/data. Once you've done that, all examples should run without issue.

Next, read Spark: The Definitive Guide excerpts, Pages 22-31.

Then, in your notebook, do the code exercises from Spark: The Definitive Guide, Chapter 3: A Tour of Spark’s Toolset, only lines 1-105. (You don't need to do the Machine Learning exercise at the end.)

Do the exercises "the hard way":

You will do the incredibly simple things that all programmers do to learn a programming language:

Go through each exercise.
Type in each exactly.
Make it run.
7. Export and commit your notebook
Export your notebook as an HTML file. Commit the file to your GitHub repo.
