{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'category_encoders'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cb6e290efde5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcategory_encoders\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnjit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'category_encoders'"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import category_encoders as ce\n",
    "from numba import njit\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ds1-predictive-modeling-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dd.read_csv('train_features.csv')\n",
    "y = dd.read_csv('train_labels.csv')\n",
    "y = y.drop([\"id\"],axis=1)\n",
    "y = y.mask(y == \"functional needs repair\", \"non functional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x.random_split([0.75,0.25],random_state =42)\n",
    "y_train, y_test = y.random_split([0.75,0.25],random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train),len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Kn = KNeighborsClassifier(n_neighbors=25,weights='distance')\n",
    "Kn.fit(x_train[[\"latitude\",\"longitude\"]],y_train)\n",
    "Kn.predict(x_train[[\"latitude\",\"longitude\"]])\n",
    "Kn.score(x_test[[\"latitude\",\"longitude\"]],y_test.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Kn = KNeighborsClassifier(n_neighbors=25,weights='distance', n_jobs=-1)\n",
    "Kn.fit(x_train[[\"latitude\",\"longitude\"]],y_train)\n",
    "Kn.predict(x_train[[\"latitude\",\"longitude\"]])\n",
    "Kn.score(x_test[[\"latitude\",\"longitude\"]],y_test.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kn.score(x_test[[\"latitude\",\"longitude\"]],y_test.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x[[\"funder\", \"installer\", \"permit\", \"scheme_management\",\"construction_year\",\"payment\",\"latitude\",\"longitude\",]]\n",
    "z = z.mask(z == 0, np.nan).mask(z == \"unknown\",np.nan)\n",
    "z = z.isna()\n",
    "z[\"poorly_documented\"] = False\n",
    "for i in z.columns.values:\n",
    "    z[\"poorly_documented\"] = (z[\"poorly_documented\"] | z[i])\n",
    "x[\"poorly_documented\"] = z[\"poorly_documented\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[\"construction_year\"] = x[\"construction_year\"].mask(x == 0,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x.random_split([0.75,0.25],random_state =42)\n",
    "y_train, y_test = y.random_split([0.75,0.25],random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [\"basin\",\"region\",\"region_code\",\"district_code\",\"scheme_management\",\"extraction_type\",\"management\",\\\n",
    "         \"extraction_type_group\",\"quantity_group\", \"payment\", \"waterpoint_type\",\"water_quality\",\"quality_group\",\"public_meeting\"\\\n",
    "        ,\"lga\",\"poorly_documented\",\"source\",\"source_class\",\"extraction_type_class\",\"management_group\",\\\n",
    "          'gps_height',\"population\",\"construction_year\"]\n",
    "cols1 = [\"basin\",\"region\",\"region_code\",\"district_code\",\"scheme_management\",\"extraction_type\",\"management\",\\\n",
    "         \"extraction_type_group\",\"quantity_group\", \"payment\", \"waterpoint_type\",\"water_quality\",\"quality_group\",\\\n",
    "         \"public_meeting\",\"lga\",\"poorly_documented\",\"source\",\"source_class\",\"extraction_type_class\", \\\n",
    "         \"top_installer\",\"management_group\", \"top_funder\"]\n",
    "class_weights = {'functional':1,'non functional':1.2,'functional needs repair':1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = make_pipeline(\n",
    "ce.OneHotEncoder(cols = c,use_cat_names=True),\n",
    "LogisticRegression(solver='lbfgs',class_weight=class_weights)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.externals import joblib   \n",
    "with joblib.parallel_backend('dask'):\n",
    "    pipeline.fit(x_train[c],y_train)\n",
    "    y_pred = pipeline.predict(x_test[c])\n",
    "    accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[\"status_group\"].value_counts().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [\"latitude\",\"longitude\",\"construction_year\"]\n",
    "from dask_ml.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train[c].values, y_train[\"status_group\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=10000,\n",
    "                           n_features=500,\n",
    "                           n_classes=2,\n",
    "                           n_redundant=250,\n",
    "                           random_state=42)\n",
    "\n",
    "from sklearn import linear_model, decomposition\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "logistic = linear_model.LogisticRegression()\n",
    "pca = decomposition.PCA()\n",
    "pipe = Pipeline(steps=[('pca', pca),\n",
    "                       ('logistic', logistic)])\n",
    "\n",
    "\n",
    "#Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "grid = dict(pca__n_components=[50, 100, 150, 250],\n",
    "            logistic__C=[1e-4, 1.0, 10, 1e4],\n",
    "            logistic__penalty=['l1', 'l2'])\n",
    "\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "from dklearn.grid_search import GridSearchCV\n",
    "\n",
    "estimator = GridSearchCV(pipe, grid)\n",
    "\n",
    "estimator.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
