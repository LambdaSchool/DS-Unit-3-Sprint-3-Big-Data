{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "\n",
    "train_feat_url = 'https://raw.githubusercontent.com/will-cotton4/A-LSDS-prediction-kaggle/master/train_features.csv'\n",
    "train_label_url = 'https://raw.githubusercontent.com/will-cotton4/A-LSDS-prediction-kaggle/master/train_labels.csv'\n",
    "test_feat_url = 'https://raw.githubusercontent.com/will-cotton4/A-LSDS-prediction-kaggle/master/test_features.csv'\n",
    "\n",
    "X = pd.read_csv(train_feat_url)\n",
    "y = pd.read_csv(train_label_url)\n",
    "X_test = pd.read_csv(test_feat_url)\n",
    "\n",
    "def wrangle_labels(y):\n",
    "  y = y.copy()\n",
    "  y = y.set_index('id')\n",
    "  label_dict = {'functional':2, 'functional needs repair': 1, 'non functional': 0}\n",
    "  y = y.replace(label_dict)\n",
    "  return y\n",
    "\n",
    "y = wrangle_labels(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, \n",
    "                                                  random_state=42, stratify=y)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "def wrangle(X):\n",
    "  X = X.copy()\n",
    "  X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
    "  X['date_recorded_month'] = X['date_recorded'].dt.month.astype('object')\n",
    "  X['date_recorded_year'] = X['date_recorded'].dt.year.astype('object')\n",
    "  X['date_recorded_day'] = X['date_recorded'].dt.day.astype('object')\n",
    "  X = X.drop(columns='date_recorded')\n",
    "  \n",
    "  imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "  X =  pd.DataFrame(imp_mode.fit_transform(X), columns=X.columns)\n",
    "  drop_cols = ['longitude', 'latitude']\n",
    "\n",
    "  #   X = X.drop(columns=drop_cols)\n",
    "#   cat_cols = X.select_dtypes(['object']).columns.tolist()\n",
    "\n",
    "#   binary_ce = ce.BinaryEncoder(cols=cat_cols, verbose=10, return_df=True)\n",
    "\n",
    "#   X = binary_ce.fit_transform(X)\n",
    "#   # Remove unnecessary/sparse features\n",
    "  \n",
    "#   drop_cols = ['longitude', 'latitude', 'region', 'recorded_by', 'wpt_name', 'num_private',\n",
    "#                'scheme_management', 'scheme_name', 'extraction_type', # Might add scheme_management back\n",
    "#               'extraction_type_group', 'quantity_group', 'quality_group'] # These group features might be useful depending on how the cat. encoding goes\n",
    "  \n",
    "  \n",
    "#   # One-hot encoding:\n",
    "#   to_one_hot = ['extraction_type_class', 'waterpoint_type_group', \n",
    "#                 'management_group', 'payment_type', 'source_class',\n",
    "#                 'basin']\n",
    "#   X = pd.get_dummies(X, prefix_sep='_', columns=to_one_hot)\n",
    "\n",
    "#   # Ordinal encoding:\n",
    "  \n",
    "#   # Binary encoding:\n",
    "#   to_binary = ['public_meeting']\n",
    "  \n",
    "#   # Future cleaning:\n",
    "#   to_be_cleaned = ['funder', 'installer', 'date_recorded', 'subvillage',\n",
    "#                   'public_meeting', 'permit', 'lga', 'ward', 'management', \n",
    "#                    'payment', 'water_quality',\n",
    "#                    'quantity', 'source', 'source_type', 'waterpoint_type']\n",
    "#   X = X.drop(columns=to_be_cleaned)\n",
    "  \n",
    "  \n",
    "  return X\n",
    "\n",
    "\n",
    "X_train = wrangle(X_train)\n",
    "X_val = wrangle(X_val)\n",
    "X_test = wrangle(X_test)\n",
    "\n",
    "cat_cols = X_train.select_dtypes(['object']).columns.tolist()\n",
    "\n",
    "binary_ce = ce.BinaryEncoder(cols=cat_cols, verbose=10, return_df=True)\n",
    "\n",
    "X_train = binary_ce.fit_transform(X_train)\n",
    "X_val = binary_ce.transform(X_val)\n",
    "X_test = binary_ce.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Kaggle RSCV code on AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.90)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xgboost) (1.1.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xgboost) (1.15.4)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: category-encoders in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.0.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category-encoders) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category-encoders) (1.15.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category-encoders) (0.20.3)\n",
      "Requirement already satisfied: pandas>=0.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category-encoders) (0.24.2)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category-encoders) (0.9.0)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category-encoders) (0.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.21.1->category-encoders) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.21.1->category-encoders) (2018.4)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from patsy>=0.4.1->category-encoders) (1.11.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "!pip install category-encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 6.68 µs\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   37.2s\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:   58.1s\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=2)]: Done  30 out of  30 | elapsed:  3.6min finished\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7944654882154882\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(100,1000), \n",
    "    'max_depth': randint(30,100)\n",
    "}\n",
    "\n",
    "gridsearch = RandomizedSearchCV(\n",
    "    RandomForestClassifier(n_jobs=-1, random_state=42), \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=10, \n",
    "    cv=3, \n",
    "    scoring='accuracy', \n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=2\n",
    ")\n",
    "\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(gridsearch.best_score_)\n",
    "\n",
    "estimator = gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.91 µs\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  30 | elapsed:   35.3s remaining:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  30 | elapsed:  1.2min remaining:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  30 | elapsed:  1.5min remaining:  2.5min\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  30 | elapsed:  1.7min remaining:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed:  2.2min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:  2.6min remaining:   48.2s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:  3.0min remaining:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  3.0min finished\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7945917508417508\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(100,1000), \n",
    "    'max_depth': randint(30,100)\n",
    "}\n",
    "\n",
    "gridsearch = RandomizedSearchCV(\n",
    "    RandomForestClassifier(n_jobs=16, random_state=42), \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=10, \n",
    "    cv=3, \n",
    "    scoring='accuracy', \n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(gridsearch.best_score_)\n",
    "\n",
    "estimator = gridsearch.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
