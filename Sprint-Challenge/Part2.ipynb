{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEzGcj3Cx7Rx",
        "colab_type": "text"
      },
      "source": [
        "**You've been introduced to a variety of platforms (AWS SageMaker, AWS EMR, Databricks), libraries (Numba, Dask, MapReduce, Spark), and languages (Python, SQL, Scala, Java) that can \"scale up\" or \"scale out\" for faster processing of big data.**\n",
        "\n",
        "**Write a paragraph comparing some of these technology options. For example, you could describe which technology you may personally prefer to use, in what circumstances, for what reasons.**\n",
        "\n",
        "- Each of these platforms and languages have their advantages, and their use are project dependent. I prefer Python as my primary programming language. It is a good general purpose language that can be used with the majority of my programming needs. SQL is great for querying a database, and it is very intuative. I like the fact that I can use SQL queries in Spark, which makes the Databricks platform a great choice for querying very large datasets. I really liked AWS SageMaker. It provides an affordable method to scale without needing to invest in additional hardware. "
      ]
    }
  ]
}